import os
import re
import uuid
import shutil
import logging
import requests
import telebot
import json
from flask import Flask, request, abort
# from faster_whisper import WhisperModel # Halkan ayaan ka saarnay faster_whisper
from datetime import datetime, timedelta
from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton
import asyncio
from msspeech import MSSpeech, MSSpeechError
import speech_recognition as sr # Ku dar SpeechRecognition
import imageio_ffmpeg as ffmpeg # Ku dar imageio_ffmpeg
from pydub import AudioSegment # Ku dar pydub si loogu chunking

# Configure logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- BOT CONFIGURATION (Using original bot's TOKEN and Webhook URL) ---
TOKEN = "7770743573:AAHHnK_Ameb8GkqgvK3LQUp3l0dN3njecN4" # Main Bot's Token

bot = telebot.TeleBot(TOKEN, threaded=True) # Set threaded to True for async operations
app = Flask(__name__)

# Admin ID
ADMIN_ID = 5978150981

# Download directory
DOWNLOAD_DIR = "downloads"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# # Whisper model for transcription - Halkan ayaan ka saarnay Whisper model
# model = WhisperModel(model_size_or_path="tiny", device="cpu", compute_type="int8")

# --- User tracking files (Combined) ---
users_file = 'users.json' # Used for last activity and TTS voice
user_data = {} # Stores last activity timestamp
user_voice_settings = {} # Stores TTS voice settings
if os.path.exists(users_file):
    with open(users_file, 'r') as f:
        try:
            loaded_data = json.load(f)
            # Differentiate between general user data and TTS specific voice settings
            user_data = {k: v for k, v in loaded_data.items() if not k.startswith("voice_")}
            user_voice_settings = {k.replace("voice_", ""): v for k, v in loaded_data.items() if k.startswith("voice_")}
        except json.JSONDecodeError:
            user_data = {}
            user_voice_settings = {}

# User-specific language settings for translate/summarize
user_language_settings_file = 'user_language_settings.json'
user_language_settings = {}
if os.path.exists(user_language_settings_file):
    with open(user_language_settings_file, 'r') as f:
        try:
            user_language_settings = json.load(f)
        except json.JSONDecodeError:
            user_language_settings = {}

# New: User-specific media language settings for speech recognition
user_media_language_settings_file = 'user_media_language_settings.json'
user_media_language_settings = {}
if os.path.exists(user_media_language_settings_file):
    with open(user_media_language_settings_file, 'r') as f:
        try:
            user_media_language_settings = json.load(f)
        except json.JSONDecodeError:
            user_media_language_settings = {}


def save_user_data():
    # Combine both user_data and user_voice_settings for single file saving
    combined_data = {**user_data}
    for uid, voice in user_voice_settings.items():
        combined_data[f"voice_{uid}"] = voice
    with open(users_file, 'w') as f:
        json.dump(combined_data, f, indent=4)

def save_user_language_settings():
    with open(user_language_settings_file, 'w') as f:
        json.dump(user_language_settings, f, indent=4)

def save_user_media_language_settings():
    with open(user_media_language_settings_file, 'w') as f:
        json.dump(user_media_language_settings, f, indent=4)


# In-memory chat history and transcription store
user_memory = {}
user_transcriptions = {} # Format: {user_id: {message_id: "transcription_text"}}

# Statistics counters (global variables)
total_files_processed = 0
total_audio_files = 0
total_voice_clips = 0
total_videos = 0
total_processing_time = 0  # in seconds
bot_start_time = datetime.now() # Kani waa waqtiga bot-ku bilaabmay

GEMINI_API_KEY = "AIzaSyAto78yGVZobxOwPXnl8wCE9ZW8Do2R8HA"

def ask_gemini(user_id, user_message):
    user_memory.setdefault(user_id, []).append({"role": "user", "text": user_message})
    history = user_memory[user_id][-10:]
    parts = [{"text": msg["text"]} for msg in history]
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"
    resp = requests.post(url, headers={'Content-Type': 'application/json'}, json={"contents": [{"parts": parts}]})
    result = resp.json()
    if "candidates" in result:
        reply = result['candidates'][0]['content']['parts'][0]['text']
        user_memory[user_id].append({"role": "model", "text": reply})
        return reply
    return "Error: " + json.dumps(result)

FILE_SIZE_LIMIT = 20 * 1024 * 1024  # 20MB
admin_state = {}

def set_bot_info():
    commands = [
        telebot.types.BotCommand("start", "Restart the bot"),
        telebot.types.BotCommand("status", "View Bot statistics"),
        telebot.types.BotCommand("help", "View instructions"),
        telebot.types.BotCommand("language", "Change preferred language for translate/summarize"),
        telebot.types.BotCommand("media_language", "Set language for media transcription"), # New command
        telebot.types.BotCommand("change_voice", "Change text-to-speech voice"),
        telebot.types.BotCommand("privacy", "View privacy notice"),
    ]
    bot.set_my_commands(commands)

    # Short description (About)
    bot.set_my_short_description(
        "Got media files? Let this free bot transcribe, summarize, and translate them in seconds! Also convert text to speech!"
    )

    # Full description (What can this bot do?)
    bot.set_my_description(
        """This bot quickly transcribes, summarizes, and translates voice messages, audio files, and videosâ€”free!
It also converts your text messages into speech using various voices.

     ðŸ”¥Enjoy free usage and start now!ðŸ‘ŒðŸ»"""
    )

def update_user_activity(user_id):
    user_data[str(user_id)] = datetime.now().isoformat()
    save_user_data()

@bot.message_handler(commands=['start'])
def start_handler(message):
    user_id = str(message.from_user.id)
    update_user_activity(message.from_user.id)
    if user_id not in user_data:
        user_data[user_id] = datetime.now().isoformat()
        save_user_data()

    if message.from_user.id == ADMIN_ID:
        keyboard = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True)
        keyboard.add("Send Broadcast", "Total Users", "/status")
        bot.send_message(message.chat.id, "Admin Panel", reply_markup=keyboard)
    else:
        # Check for first_name, then username, then default to "user"
        display_name = message.from_user.first_name or (f"@{message.from_user.username}" if message.from_user.username else "user")
        bot.send_message(
            message.chat.id,
            f"""ðŸ‘‹ðŸ» Welcome dear {display_name}!
I'm your all-in-one bot for media transcription and text-to-speech.
â€¢ Send me:
â€¢ Voice message
â€¢ Video message
â€¢ Audio file
â€¢ to transcribe for free
â€¢ Or simply send me a **text message** to convert it to speech!
Use /change_voice to pick your preferred speaking voice.
**Before sending a media file for transcription, use /media_language to set the language of the audio.**
"""
        )
    # Halkan waxaan ka saarnay status_handler(message) si aanay ugu soo dirin si otomaatig ah


@bot.message_handler(commands=['help'])
def help_handler(message):
    help_text = (
        """â„¹ï¸ How to use this bot:

This bot transcribes voice messages, audio files, and videos, and converts text to speech.

1.  **Send a File for Transcription:** Send a voice message, audio, or video.
    * **IMPORTANT:** Before sending, use `/media_language` to set the language of the audio file to ensure accurate transcription.
    * The bot will process your input and send back the transcribed text. Long transcriptions will be sent as a text file.
    * After transcription, you'll see options to **Translate** or **Summarize** the text.
2.  **Send Text for Speech:** Simply send any text message.
    * The bot will convert your text into an audio message.
    * Use `/change_voice` to select your preferred speaking voice.
3.  **Commands:**
    -   `/start`: Restart the bot.
    -   `/status`: View bot statistics.
    -   `/help`: Display these instructions.
    -   `/language`: Change your preferred language for translations and summaries.
    -   `/media_language`: Set the language of the audio in your media files for transcription.
    -   `/change_voice`: Select the voice for text-to-speech.
    -   `/privacy`: View the bot's privacy notice.

Enjoy transcribing your media and generating speech quickly and easily!"""
    )
    bot.send_message(message.chat.id, help_text, parse_mode="Markdown")

@bot.message_handler(commands=['privacy'])
def privacy_notice_handler(message):
    privacy_text = (
        """**Privacy Notice**

Your privacy is important to us. Here's how this bot handles your data:

1.  **Data We Process:**
    * **Media Files:** Voice messages, audio files, video files, and TikTok links you send are temporarily processed for transcription. These files are **deleted immediately** after processing. We do not store your media content.
    * **Text for TTS:** Text you send for conversion to speech is processed to generate audio and is not permanently stored.
    * **Transcriptions:** The text transcriptions generated from your media are stored temporarily in memory for subsequent actions (like translation or summarization) for a limited time (e.g., until a new transcription is made or the bot is restarted). We do not permanently store your transcription data on our servers.
    * **User IDs:** Your Telegram User ID is stored to manage your language and voice preferences and track basic activity (like last seen) to improve bot service and provide aggregated usage statistics. This ID is not linked to any personal identifying information outside of Telegram.
    * **Language & Voice Preferences:** Your chosen language for translations/summaries and your preferred text-to-speech voice are stored so you don't have to select them each time. Your **media transcription language** preference is also stored.

2.  **How We Use Your Data:**
    * To provide the core functionality of the bot: transcription, translation, summarization, and text-to-speech.
    * To improve bot performance and understand usage patterns through anonymous, aggregated statistics (e.g., total files processed).
    * To set your preferred language and voice for future interactions.

3.  **Data Sharing:**
    * We **do not share** your personal data, media files, or transcriptions with any third parties.
    * Transcription, translation, summarization, and text-to-speech are performed using integrated AI models (Google Speech API, Gemini API, MSSpeech API). Your input to these models is handled according to their respective privacy policies, but we do not store this data after processing.

4.  **Data Retention:**
    * Media files are deleted immediately after transcription.
    * Text for TTS is not stored after processing.
    * Transcriptions are held temporarily in memory.
    * User IDs, language, and voice preferences are retained to maintain your settings and usage statistics. You can always delete your data by stopping using the bot or contacting the bot administrator.

By using this bot, you agree to the terms outlined in this Privacy Notice.

If you have any questions, please contact the bot administrator."""
    )
    bot.send_message(message.chat.id, privacy_text, parse_mode="Markdown")


@bot.message_handler(commands=['status'])
def status_handler(message):
    update_user_activity(message.from_user.id)

    # Calculate bot uptime
    uptime = datetime.now() - bot_start_time
    days = uptime.days
    hours, remainder = divmod(uptime.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)

    # Count active users today
    today = datetime.now().date()
    active_today = sum(
        1 for timestamp in user_data.values()
        if datetime.fromisoformat(timestamp).date() == today
    )

    # Calculate total processing time components
    total_proc_seconds = int(total_processing_time)
    proc_hours = total_proc_seconds // 3600
    proc_minutes = (total_proc_seconds % 3600) // 60
    proc_seconds = total_proc_seconds % 60

    text = (
        "ðŸ“Š Bot Statistics\n\n"
        "ðŸŸ¢ **Bot Status: Online**\n"
        f"â³ Uptime: {days} days, {hours} hours, {minutes} minutes, {seconds} seconds\n\n"
        "ðŸ‘¥ User Statistics\n"
        f"â–«ï¸ Total Users Today: {active_today}\n"
        f"â–«ï¸ Total Registered Users: {len(user_data)}\n\n"
        "âš™ï¸ Processing Statistics\n"
        f"â–«ï¸ Total Files Processed: {total_files_processed}\n"
        f"â–«ï¸ Audio Files: {total_audio_files}\n"
        f"â–«ï¸ Voice Clips: {total_voice_clips}\n"
        f"â–«ï¸ Videos: {total_videos}\n"
        f"â±ï¸ Total Processing Time: {proc_hours} hours {proc_minutes} minutes {proc_seconds} seconds\n\n"
        "â¸»\n\n"
        "Thanks for using our service! ðŸ™Œ"
    )

    bot.send_message(message.chat.id, text, parse_mode="Markdown")

@bot.message_handler(func=lambda m: m.text == "Total Users" and m.from_user.id == ADMIN_ID)
def total_users(message):
    bot.send_message(message.chat.id, f"Total registered users: {len(user_data)}")

@bot.message_handler(func=lambda m: m.text == "Send Broadcast" and m.from_user.id == ADMIN_ID)
def send_broadcast(message):
    admin_state[message.from_user.id] = 'awaiting_broadcast'
    bot.send_message(message.chat.id, "Send the broadcast message now:")

@bot.message_handler(
    func=lambda m: m.from_user.id == ADMIN_ID and admin_state.get(m.from_user.id) == 'awaiting_broadcast',
    content_types=['text', 'photo', 'video', 'audio', 'document']
)
def broadcast_message(message):
    admin_state[message.from_user.id] = None
    success = fail = 0
    for uid_key in user_data: # Iterate through keys in user_data
        uid = uid_key # Use the key directly as user ID
        try:
            bot.copy_message(uid, message.chat.id, message.message_id)
            success += 1
        except telebot.apihelper.ApiTelegramException as e:
            logging.error(f"Failed to send broadcast to {uid}: {e}")
            fail += 1
    bot.send_message(
        message.chat.id,
        f"Broadcast complete.\nSuccessful: {success}\nFailed: {fail}"
    )

@bot.message_handler(content_types=['voice', 'audio', 'video', 'video_note'])
def handle_file(message):
    global total_files_processed, total_audio_files, total_voice_clips, total_videos, total_processing_time
    update_user_activity(message.from_user.id)
    uid = str(message.from_user.id)

    # Check if user has set a media language
    if uid not in user_media_language_settings:
        bot.send_message(message.chat.id,
                         "âš ï¸ Fadlan marka hore soo dooro luqadda feylka maqalka ah adoo isticmaalaya /media_language ka hor intaadan soo dirin feylka.")
        return

    # Add reaction emoji based on file type
    try:
        if message.voice:
            bot.set_message_reaction(chat_id=message.chat.id, message_id=message.message_id, reaction=["ðŸ‘€"])
        elif message.audio:
            bot.set_message_reaction(chat_id=message.chat.id, message_id=message.message_id, reaction=["ðŸ‘€"])
        elif message.video or message.video_note:
            bot.set_message_reaction(chat_id=message.chat.id, message_id=message.message_id, reaction=["ðŸ‘€"])
    except Exception as e:
        logging.error(f"Error setting reaction: {e}")

    file_obj = message.voice or message.audio or message.video or message.video_note
    if file_obj.file_size > FILE_SIZE_LIMIT:
        return bot.send_message(message.chat.id, "The file size you uploaded is too large (max allowed is 20MB).")

    info = bot.get_file(file_obj.file_id)
    # Save as .ogg for Telegram voice/video notes, or original extension for audio/video
    file_extension = ".ogg" if message.voice or message.video_note else os.path.splitext(info.file_path)[1]
    local_path = os.path.join(DOWNLOAD_DIR, f"{uuid.uuid4()}{file_extension}")
    bot.send_chat_action(message.chat.id, 'typing')

    try:
        data = bot.download_file(info.file_path)
        with open(local_path, 'wb') as f:
            f.write(data)

        bot.send_chat_action(message.chat.id, 'typing')
        processing_start_time = datetime.now()

        # Convert to WAV for SpeechRecognition
        wav_path = os.path.join(DOWNLOAD_DIR, f"{uuid.uuid4()}.wav")
        try:
            # Use imageio_ffmpeg for conversion
            os.system(f'{ffmpeg.get_ffmpeg_exe()} -i "{local_path}" -vn -acodec pcm_s16le -ar 16000 -ac 1 "{wav_path}"')
            if not os.path.exists(wav_path) or os.path.getsize(wav_path) == 0:
                raise Exception("FFmpeg conversion failed or resulted in empty file.")
        except Exception as e:
            logging.error(f"FFmpeg conversion failed: {e}")
            bot.send_message(message.chat.id, "âš ï¸ Fayoobkaaga lama beddeli karo qaabka saxda ah ee aqoonsiga codka.")
            if os.path.exists(local_path):
                os.remove(local_path)
            return

        # Get preferred media language
        media_lang_code = get_lang_code(user_media_language_settings[uid]) # Get the language code for SpeechRecognition
        if not media_lang_code:
            bot.send_message(message.chat.id, f"âŒ Luqadda *{user_media_language_settings[uid]}* looma helin koodh sax ah. Fadlan dib u dooro luqadda.")
            if os.path.exists(local_path): os.remove(local_path)
            if os.path.exists(wav_path): os.remove(wav_path)
            return

        transcription = transcribe_audio_chunks(wav_path, media_lang_code) or ""
        # uid = str(message.from_user.id) # Already defined

        user_transcriptions.setdefault(uid, {})[message.message_id] = transcription

        total_files_processed += 1
        if message.voice:
            total_voice_clips += 1
        elif message.audio:
            total_audio_files += 1
        elif message.video or message.video_note:
            total_videos += 1

        processing_time = (datetime.now() - processing_start_time).total_seconds()
        total_processing_time += processing_time

        buttons = InlineKeyboardMarkup()
        buttons.add(
            InlineKeyboardButton("Translate ", callback_data=f"btn_translate|{message.message_id}"),
            InlineKeyboardButton("Summarize ", callback_data=f"btn_summarize|{message.message_id}")
        )
        # Add Speak button for transcription
        buttons.add(InlineKeyboardButton("Speak this text ðŸ”Š", callback_data=f"btn_speak_transcription|{message.message_id}"))


        if len(transcription) > 4000:
            fn = 'transcription.txt'
            with open(fn, 'w', encoding='utf-8') as f:
                f.write(transcription)
            bot.send_chat_action(message.chat.id, 'upload_document')
            with open(fn, 'rb') as doc:
                bot.send_document(
                    message.chat.id,
                    doc,
                    reply_to_message_id=message.message_id,
                    reply_markup=buttons,
                    caption="Hereâ€™s your transcription. Tap a button below for more options."
                )
            os.remove(fn)
        else:
            bot.reply_to(
                message,
                transcription,
                reply_markup=buttons
            )
    except Exception as e:
        logging.error(f"Error processing file: {e}")
        bot.send_message(message.chat.id, "âš ï¸ An error occurred during transcription.")
    finally:
        if os.path.exists(local_path):
            os.remove(local_path)
        if os.path.exists(wav_path):
            os.remove(wav_path) # Clean up the WAV file

# --- Language Selection and Saving ---

# List of common languages with emojis (ordered by approximate global prevalence/popularity)
LANGUAGES = [
    {"name": "English", "flag": "ðŸ‡¬ðŸ‡§", "code": "en-US"},
    {"name": "Chinese", "flag": "ðŸ‡¨ðŸ‡³", "code": "zh-CN"},
    {"name": "Spanish", "flag": "ðŸ‡ªðŸ‡¸", "code": "es-ES"},
    {"name": "Hindi", "flag": "ðŸ‡®ðŸ‡³", "code": "hi-IN"},
    {"name": "Arabic", "flag": "ðŸ‡¸ðŸ‡¦", "code": "ar-SA"},
    {"name": "French", "flag": "ðŸ‡«ðŸ‡·", "code": "fr-FR"},
    {"name": "Bengali", "flag": "ðŸ‡§ðŸ‡©", "code": "bn-BD"}, # Added Bangladesh for Bengali
    {"name": "Russian", "flag": "ðŸ‡·ðŸ‡º", "code": "ru-RU"},
    {"name": "Portuguese", "flag": "ðŸ‡µðŸ‡¹", "code": "pt-PT"}, # Portugal for Portuguese
    {"name": "Urdu", "flag": "ðŸ‡µðŸ‡°", "code": "ur-PK"},
    {"name": "German", "flag": "ðŸ‡©ðŸ‡ª", "code": "de-DE"},
    {"name": "Japanese", "flag": "ðŸ‡¯ðŸ‡µ", "code": "ja-JP"},
    {"name": "Korean", "flag": "ðŸ‡°ðŸ‡·", "code": "ko-KR"},
    {"name": "Vietnamese", "flag": "ðŸ‡»ðŸ‡³", "code": "vi-VN"},
    {"name": "Turkish", "flag": "ðŸ‡¹ðŸ‡·", "code": "tr-TR"},
    {"name": "Italian", "flag": "ðŸ‡®ðŸ‡¹", "code": "it-IT"},
    {"name": "Thai", "flag": "ðŸ‡¹ðŸ‡­", "code": "th-TH"},
    {"name": "Swahili", "flag": "ðŸ‡°ðŸ‡ª", "code": "sw-KE"},
    {"name": "Dutch", "flag": "ðŸ‡³ðŸ‡±", "code": "nl-NL"},
    {"name": "Polish", "flag": "ðŸ‡µðŸ‡±", "code": "pl-PL"},
    {"name": "Ukrainian", "flag": "ðŸ‡ºðŸ‡¦", "code": "uk-UA"},
    {"name": "Indonesian", "flag": "ðŸ‡®ðŸ‡©", "code": "id-ID"},
    {"name": "Malay", "flag": "ðŸ‡²ðŸ‡¾", "code": "ms-MY"},
    {"name": "Filipino", "flag": "ðŸ‡µðŸ‡­", "code": "fil-PH"}, # Filipino (Tagalog)
    {"name": "Persian", "flag": "ðŸ‡®ðŸ‡·", "code": "fa-IR"}, # Farsi (Persian)
    {"name": "Amharic", "flag": "ðŸ‡ªðŸ‡¹", "code": "am-ET"},
    {"name": "Somali", "flag": "ðŸ‡¸ðŸ‡´", "code": "so-SO"}, # Somali
    {"name": "Swedish", "flag": "ðŸ‡¸ðŸ‡ª", "code": "sv-SE"},
    {"name": "Norwegian", "flag": "ðŸ‡³ðŸ‡´", "code": "nb-NO"}, # Norwegian BokmÃ¥l
    {"name": "Danish", "flag": "ðŸ‡©ðŸ‡°", "code": "da-DK"},
    {"name": "Finnish", "flag": "ðŸ‡«ðŸ‡®", "code": "fi-FI"},
    {"name": "Greek", "flag": "ðŸ‡¬ðŸ‡·", "code": "el-GR"},
    {"name": "Hebrew", "flag": "ðŸ‡®ðŸ‡±", "code": "he-IL"},
    {"name": "Czech", "flag": "ðŸ‡¨ðŸ‡¿", "code": "cs-CZ"},
    {"name": "Hungarian", "flag": "ðŸ‡­ðŸ‡º", "code": "hu-HU"},
    {"name": "Romanian", "flag": "ðŸ‡·ðŸ‡´", "code": "ro-RO"},
    {"name": "Nepali", "flag": "ðŸ‡³ðŸ‡µ", "code": "ne-NP"},
    {"name": "Sinhala", "flag": "ðŸ‡±ðŸ‡°", "code": "si-LK"},
    {"name": "Tamil", "flag": "ðŸ‡®ðŸ‡³", "code": "ta-IN"},
    {"name": "Telugu", "flag": "ðŸ‡®ðŸ‡³", "code": "te-IN"},
    {"name": "Kannada", "flag": "ðŸ‡®ðŸ‡³", "code": "kn-IN"},
    {"name": "Malayalam", "flag": "ðŸ‡®ðŸ‡³", "code": "ml-IN"},
    {"name": "Gujarati", "flag": "ðŸ‡®ðŸ‡³", "code": "gu-IN"},
    {"name": "Punjabi", "flag": "ðŸ‡®ðŸ‡³", "code": "pa-IN"},
    {"name": "Marathi", "flag": "ðŸ‡®ðŸ‡³", "code": "mr-IN"},
    {"name": "Oriya", "flag": "ðŸ‡®ðŸ‡³", "code": "or-IN"},
    {"name": "Assamese", "flag": "ðŸ‡®ðŸ‡³", "code": "as-IN"},
    {"name": "Khmer", "flag": "ðŸ‡°ðŸ‡­", "code": "km-KH"},
    {"name": "Lao", "flag": "ðŸ‡±ðŸ‡¦", "code": "lo-LA"},
    {"name": "Burmese", "flag": "ðŸ‡²ðŸ‡²", "code": "my-MM"},
    {"name": "Georgian", "flag": "ðŸ‡¬ðŸ‡ª", "code": "ka-GE"},
    {"name": "Armenian", "flag": "ðŸ‡¦ðŸ‡²", "code": "hy-AM"},
    {"name": "Azerbaijani", "flag": "ðŸ‡¦ðŸ‡¿", "code": "az-AZ"},
    {"name": "Kazakh", "flag": "ðŸ‡°ðŸ‡¿", "code": "kk-KZ"},
    {"name": "Uzbek", "flag": "ðŸ‡ºðŸ‡¿", "code": "uz-UZ"},
    {"name": "Kyrgyz", "flag": "ðŸ‡°ðŸ‡¬", "code": "ky-KG"},
    {"name": "Tajik", "flag": "ðŸ‡¹ðŸ‡¯", "code": "tg-TJ"},
    {"name": "Turkmen", "flag": "ðŸ‡¹ðŸ‡²", "code": "tk-TM"},
    {"name": "Mongolian", "flag": "ðŸ‡²ðŸ‡³", "code": "mn-MN"},
    {"name": "Estonian", "flag": "ðŸ‡ªðŸ‡ª", "code": "et-EE"},
    {"name": "Latvian", "flag": "ðŸ‡±ðŸ‡»", "code": "lv-LV"},
    {"name": "Lithuanian", "flag": "ðŸ‡±ðŸ‡¹", "code": "lt-LT"},
    {"name": "Afrikaans", "flag": "ðŸ‡¿ðŸ‡¦", "code": "af-ZA"}, # Afrikaans
    {"name": "Albanian", "flag": "ðŸ‡¦ðŸ‡±", "code": "sq-AL"}, # Albanian
    {"name": "Bosnian", "flag": "ðŸ‡§ðŸ‡¦", "code": "bs-BA"}, # Bosnian
    {"name": "Bulgarian", "flag": "ðŸ‡§ðŸ‡¬", "code": "bg-BG"}, # Bulgarian
    {"name": "Catalan", "flag": "ðŸ‡ªðŸ‡¸", "code": "ca-ES"}, # Catalan
    {"name": "Croatian", "flag": "ðŸ‡­ðŸ‡·", "code": "hr-HR"}, # Croatian
    {"name": "Estonian", "flag": "ðŸ‡ªðŸ‡ª", "code": "et-EE"}, # Estonian (already listed)
    {"name": "Galician", "flag": "ðŸ‡ªðŸ‡¸", "code": "gl-ES"}, # Galician
    {"name": "Icelandic", "flag": "ðŸ‡®ðŸ‡¸", "code": "is-IS"}, # Icelandic
    {"name": "Irish", "flag": "ðŸ‡®ðŸ‡ª", "code": "ga-IE"}, # Irish
    {"name": "Macedonian", "flag": "ðŸ‡²ðŸ‡°", "code": "mk-MK"}, # Macedonian
    {"name": "Maltese", "flag": "ðŸ‡²ðŸ‡¹", "code": "mt-MT"}, # Maltese
    {"name": "Serbian", "flag": "ðŸ‡·ðŸ‡¸", "code": "sr-RS"}, # Serbian
    {"name": "Slovak", "flag": "ðŸ‡¸ðŸ‡°", "code": "sk-SK"}, # Slovak
    {"name": "Slovenian", "flag": "ðŸ‡¸ðŸ‡®", "code": "sl-SI"}, # Slovenian
    {"name": "Urdu", "flag": "ðŸ‡µðŸ‡°", "code": "ur-PK"}, # Urdu (already listed)
    {"name": "Welsh", "flag": "ðŸ´ó §ó ¢ó ·ó ¬ó ³ó ¿", "code": "cy-GB"}, # Welsh
    {"name": "Zulu", "flag": "ðŸ‡¿ðŸ‡¦", "code": "zu-ZA"}, # Zulu
]

# Function to get language code from language name
def get_lang_code(lang_name):
    for lang in LANGUAGES:
        if lang['name'].lower() == lang_name.lower():
            return lang['code']
    return None

def generate_language_keyboard(callback_prefix, message_id=None):
    markup = InlineKeyboardMarkup(row_width=3)
    buttons = []
    for lang in LANGUAGES:
        cb_data = f"{callback_prefix}|{lang['name']}"
        if message_id is not None:
            cb_data += f"|{message_id}"
        buttons.append(InlineKeyboardButton(f"{lang['name']} {lang['flag']}", callback_data=cb_data))
    markup.add(*buttons)
    return markup

@bot.message_handler(commands=['language'])
def select_language_command(message):
    uid = str(message.from_user.id)
    update_user_activity(uid)

    markup = generate_language_keyboard("set_lang")
    bot.send_message(
        message.chat.id,
        "Please select your preferred language for future **translations and summaries**:",
        reply_markup=markup
    )

@bot.callback_query_handler(func=lambda c: c.data.startswith("set_lang|"))
def callback_set_language(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    _, lang = call.data.split("|", 1)
    user_language_settings[uid] = lang
    save_user_language_settings()
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"âœ… Your preferred language for translations and summaries has been set to: **{lang}**",
        parse_mode="Markdown"
    )
    bot.answer_callback_query(call.id, text=f"Language set to {lang}")


# NEW: Command for setting media transcription language
@bot.message_handler(commands=['media_language'])
def select_media_language_command(message):
    uid = str(message.from_user.id)
    update_user_activity(uid)

    markup = generate_language_keyboard("set_media_lang")
    bot.send_message(
        message.chat.id,
        "Fadlan dooro luqadda feylasha maqalka ah ee aad u baahan tahay inaan u beddelo qoraal. Tani waxay caawinaysaa akhrinta saxda ah.",
        reply_markup=markup
    )

@bot.callback_query_handler(func=lambda c: c.data.startswith("set_media_lang|"))
def callback_set_media_language(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    _, lang = call.data.split("|", 1)
    user_media_language_settings[uid] = lang
    save_user_media_language_settings()
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"âœ… Luqadda cod-qorista (transcription) ee warbaahintaada waxaa loo dejiyay: **{lang}**",
        parse_mode="Markdown"
    )
    bot.answer_callback_query(call.id, text=f"Media language set to {lang}")


@bot.callback_query_handler(func=lambda c: c.data.startswith("btn_translate|"))
def button_translate_handler(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    _, message_id_str = call.data.split("|", 1)
    message_id = int(message_id_str)

    if uid not in user_transcriptions or message_id not in user_transcriptions[uid]:
        bot.answer_callback_query(call.id, "âŒ No transcription found for this message.")
        return

    preferred_lang = user_language_settings.get(uid)
    if preferred_lang:
        bot.answer_callback_query(call.id, "Translating with your preferred language...")
        do_translate_with_saved_lang(call.message, uid, preferred_lang, message_id)
    else:
        markup = generate_language_keyboard("translate_to", message_id)
        bot.edit_message_text(
            chat_id=call.message.chat.id,
            message_id=call.message.message_id,
            text="Please select the language you want to translate into:",
            reply_markup=markup
        )
    bot.answer_callback_query(call.id)

@bot.callback_query_handler(func=lambda c: c.data.startswith("btn_summarize|"))
def button_summarize_handler(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    _, message_id_str = call.data.split("|", 1)
    message_id = int(message_id_str)

    if uid not in user_transcriptions or message_id not in user_transcriptions[uid]:
        bot.answer_callback_query(call.id, "âŒ No transcription found for this message.")
        return

    preferred_lang = user_language_settings.get(uid)
    if preferred_lang:
        bot.answer_callback_query(call.id, "Summarizing with your preferred language...")
        do_summarize_with_saved_lang(call.message, uid, preferred_lang, message_id)
    else:
        markup = generate_language_keyboard("summarize_in", message_id)
        bot.edit_message_text(
            chat_id=call.message.chat.id,
            message_id=call.message.message_id,
            text="Please select the language you want the summary in:",
            reply_markup=markup
        )
    bot.answer_callback_query(call.id)

@bot.callback_query_handler(func=lambda c: c.data.startswith("translate_to|"))
def callback_translate_to(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    parts = call.data.split("|")
    lang = parts[1]
    message_id = int(parts[2]) if len(parts) > 2 else None

    user_language_settings[uid] = lang
    save_user_language_settings()
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"Translating to **{lang}**...",
        parse_mode="Markdown"
    )
    if message_id:
        do_translate_with_saved_lang(call.message, uid, lang, message_id)
    else:
        if uid in user_transcriptions and call.message.reply_to_message and call.message.reply_to_message.message_id in user_transcriptions[uid]:
             do_translate_with_saved_lang(call.message, uid, lang, call.message.reply_to_message.message_id)
        else:
            bot.send_message(call.message.chat.id, "âŒ No transcription found for this message to translate. Please use the inline buttons on the transcription.")
    bot.answer_callback_query(call.id)

@bot.callback_query_handler(func=lambda c: c.data.startswith("summarize_in|"))
def callback_summarize_in(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    parts = call.data.split("|")
    lang = parts[1]
    message_id = int(parts[2]) if len(parts) > 2 else None

    user_language_settings[uid] = lang
    save_user_language_settings()
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"Summarizing in **{lang}**...",
        parse_mode="Markdown"
    )
    if message_id:
        do_summarize_with_saved_lang(call.message, uid, lang, message_id)
    else:
        if uid in user_transcriptions and call.message.reply_to_message and call.message.reply_to_message.message_id in user_transcriptions[uid]:
            do_summarize_with_saved_lang(call.message, uid, lang, call.message.reply_to_message.message_id)
        else:
            bot.send_message(call.message.chat.id, "âŒ No transcription found for this message to summarize. Please use the inline buttons on the transcription.")
    bot.answer_callback_query(call.id)

def do_translate_with_saved_lang(message, uid, lang, message_id):
    original = user_transcriptions.get(uid, {}).get(message_id, "")
    if not original:
        bot.send_message(message.chat.id, "âŒ No transcription available for this specific message to translate.")
        return

    prompt = f"Translate the following text into {lang}. Provide only the translated text, with no additional notes, explanations, or introductory/concluding remarks:\n\n{original}"

    bot.send_chat_action(message.chat.id, 'typing')
    translated = ask_gemini(uid, prompt)

    if translated.startswith("Error:"):
        bot.send_message(message.chat.id, f"Error during translation: {translated}")
        return

    if len(translated) > 4000:
        fn = 'translation.txt'
        with open(fn, 'w', encoding='utf-8') as f:
            f.write(translated)
        bot.send_chat_action(message.chat.id, 'upload_document')
        with open(fn, 'rb') as doc:
            bot.send_document(message.chat.id, doc, caption=f"Translation to {lang}", reply_to_message_id=message_id)
        os.remove(fn)
    else:
        bot.send_message(message.chat.id, translated, reply_to_message_id=message_id)

def do_summarize_with_saved_lang(message, uid, lang, message_id):
    original = user_transcriptions.get(uid, {}).get(message_id, "")
    if not original:
        bot.send_message(message.chat.id, "âŒ No transcription available for this specific message to summarize.")
        return

    prompt = f"Summarize the following text in {lang}. Provide only the summarized text, with no additional notes, explanations, or different versions:\n\n{original}"

    bot.send_chat_action(message.chat.id, 'typing')
    summary = ask_gemini(uid, prompt)

    if summary.startswith("Error:"):
        bot.send_message(message.chat.id, f"Error during summarization: {summary}")
        return

    if len(summary) > 4000:
        fn = 'summary.txt'
        with open(fn, 'w', encoding='utf-8') as f:
            f.write(summary)
        bot.send_chat_action(message.chat.id, 'upload_document')
        with open(fn, 'rb') as doc:
            bot.send_document(message.chat.id, doc, caption=f"Summary in {lang}", reply_to_message_id=message_id)
        os.remove(fn)
    else:
        bot.send_message(message.chat.id, summary, reply_to_message_id=message_id)


@bot.message_handler(commands=['translate'])
def handle_translate(message):
    uid = str(message.from_user.id)
    update_user_activity(uid)

    if not message.reply_to_message or uid not in user_transcriptions or message.reply_to_message.message_id not in user_transcriptions[uid]:
        return bot.send_message(message.chat.id, "âŒ Please reply to a transcription message to translate it.")

    transcription_message_id = message.reply_to_message.message_id
    preferred_lang = user_language_settings.get(uid)
    if preferred_lang:
        do_translate_with_saved_lang(message, uid, preferred_lang, transcription_message_id)
    else:
        markup = generate_language_keyboard("translate_to", transcription_message_id)
        bot.send_message(
            message.chat.id,
            "Please select the language you want to translate into:",
            reply_markup=markup
        )

@bot.message_handler(commands=['summarize'])
def handle_summarize(message):
    uid = str(message.from_user.id)
    update_user_activity(uid)

    if not message.reply_to_message or uid not in user_transcriptions or message.reply_to_message.message_id not in user_transcriptions[uid]:
        return bot.send_message(message.chat.id, "âŒ Please reply to a transcription message to summarize it.")

    transcription_message_id = message.reply_to_message.message_id
    preferred_lang = user_language_settings.get(uid)
    if preferred_lang:
        do_summarize_with_saved_lang(message, uid, preferred_lang, transcription_message_id)
    else:
        markup = generate_language_keyboard("summarize_in", transcription_message_id)
        bot.send_message(
            message.chat.id,
            "Please select the language you want the summary in:",
            reply_markup=markup
        )

# Modified transcribe function to use SpeechRecognition with chunking
def transcribe_audio_chunks(audio_path: str, lang_code: str) -> str | None:
    r = sr.Recognizer()
    full_transcription = []
    chunk_length_ms = 10000  # 10 seconds (changed from 25 seconds)
    overlap_ms = 500  # 0.5 seconds overlap

    try:
        audio = AudioSegment.from_wav(audio_path)
        total_length_ms = len(audio)
        start_ms = 0

        logging.info(f"Starting chunking for {audio_path}, total length {total_length_ms / 1000} seconds.")

        while start_ms < total_length_ms:
            end_ms = min(start_ms + chunk_length_ms, total_length_ms)
            chunk = audio[start_ms:end_ms]
            chunk_file = os.path.join(DOWNLOAD_DIR, f"chunk_{uuid.uuid4()}.wav")
            chunk.export(chunk_file, format="wav")

            with sr.AudioFile(chunk_file) as source:
                try:
                    audio_listened = r.record(source)
                    # Use Google Speech Recognition API
                    text = r.recognize_google(audio_listened, language=lang_code)
                    full_transcription.append(text)
                    logging.info(f"Transcribed chunk from {start_ms/1000}s to {end_ms/1000}s: {text[:50]}...")
                except sr.UnknownValueError:
                    logging.warning(f"Speech Recognition could not understand audio in chunk {start_ms/1000}s - {end_ms/1000}s")
                except sr.RequestError as e:
                    logging.error(f"Could not request results from Google Speech Recognition service; {e} for chunk {start_ms/1000}s - {end_ms/1000}s")
                except Exception as e:
                    logging.error(f"Error processing chunk {start_ms/1000}s - {end_ms/1000}s: {e}")
                finally:
                    if os.path.exists(chunk_file):
                        os.remove(chunk_file)

            start_ms += chunk_length_ms - overlap_ms # Move to next chunk with overlap

        return " ".join(full_transcription) if full_transcription else None
    except Exception as e:
        logging.error(f"Overall transcription error: {e}")
        return None

# --- NEW: TEXT-TO-SPEECH FUNCTIONALITY (Integrated from the second bot) ---

# Group voices by language for better organization
VOICES_BY_LANGUAGE = {
    "English ðŸ‡¬ðŸ‡§": [
        "en-US-AriaNeural", "en-US-GuyNeural",
        "en-GB-LibbyNeural", "en-GB-RyanNeural",
    ],
    "Somali ðŸ‡¸ðŸ‡´": [
        "so-SO-UbaxNeural", "so-SO-MuuseNeural",
    ],
    # Add other languages if needed
}

def get_user_tts_voice(uid):
    # Default to a specific voice if not found in user settings
    return user_voice_settings.get(str(uid), "en-US-AriaNeural") # Default English voice

def make_language_keyboard_tts():
    kb = InlineKeyboardMarkup(row_width=1)
    for lang_name in VOICES_BY_LANGUAGE.keys():
        kb.add(InlineKeyboardButton(lang_name, callback_data=f"tts_lang|{lang_name}"))
    return kb

def make_voice_keyboard_for_language_tts(lang_name):
    kb = InlineKeyboardMarkup(row_width=2)
    voices = VOICES_BY_LANGUAGE.get(lang_name, [])
    for voice in voices:
        kb.add(InlineKeyboardButton(voice, callback_data=f"tts_voice|{voice}"))
    kb.add(InlineKeyboardButton("â¬…ï¸ Back to Languages", callback_data="tts_back_to_languages"))
    return kb

# ====== TEXT-TO-SPEECH SYNTHESIS ======
async def a_main_tts(voice, text, filename, rate=0, pitch=0, volume=1.0):
    mss = MSSpeech()
    await mss.set_voice(voice)
    await mss.set_rate(rate)
    await mss.set_pitch(pitch)
    await mss.set_volume(volume)
    return await mss.synthesize(text, filename)

async def synth_and_send_tts(chat_id, user_id, text_to_speak, reply_to_message_id=None):
    voice = get_user_tts_voice(user_id)
    filename = os.path.join(DOWNLOAD_DIR, f"tts_{user_id}_{uuid.uuid4()}.mp3") # Use DOWNLOAD_DIR for TTS
    logging.info(f"Synthesizing text for user {user_id} with voice {voice}")
    try:
        bot.send_chat_action(chat_id, "record_audio")
        await a_main_tts(voice, text_to_speak, filename)
        if not os.path.exists(filename) or os.path.getsize(filename) == 0:
            bot.send_message(chat_id, "âŒ MP3 file not generated or empty. Please try again.")
            return

        with open(filename, "rb") as f:
            bot.send_audio(chat_id, f, caption=f"ðŸŽ¤ Voice: {voice}", reply_to_message_id=reply_to_message_id)
    except MSSpeechError as e:
        logging.error(f"MSSpeech TTS error for user {user_id}: {e}")
        bot.send_message(chat_id, f"âŒ Wuu jiraa khalad dhinaca codka ah: {e}")
    except Exception as e:
        logging.exception(f"Unexpected TTS error for user {user_id}")
        bot.send_message(chat_id, "âŒ Wuxuu dhacay khalad aan la filayn. Fadlan isku day mar kale.")
    finally:
        if os.path.exists(filename):
            os.remove(filename) # Clean up the audio file

# --- TTS Command Handlers ---
@bot.message_handler(commands=["change_voice"])
def cmd_change_voice(message):
    update_user_activity(message.from_user.id)
    bot.send_message(message.chat.id, "ðŸŽ™ï¸ Choose a language for Text-to-Speech:", reply_markup=make_language_keyboard_tts())

@bot.callback_query_handler(func=lambda c: c.data.startswith("tts_lang|"))
def on_language_select_tts(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    _, lang_name = call.data.split("|", 1)
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"ðŸŽ™ï¸ Choose a voice for {lang_name}:",
        reply_markup=make_voice_keyboard_for_language_tts(lang_name)
    )
    bot.answer_callback_query(call.id)

@bot.callback_query_handler(func=lambda c: c.data.startswith("tts_voice|"))
def on_voice_change_tts(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    _, voice = call.data.split("|", 1)
    user_voice_settings[uid] = voice
    save_user_data() # Save the combined user data
    bot.answer_callback_query(call.id, f"âœ”ï¸ Voice changed to {voice}")
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"ðŸ”Š Hadda waxaad isticmaalaysaa: *{voice}*. Waxaad bilaabi kartaa inaad qorto qoraalka. (Fadlan fariin cusub soo dir, ha ahaan jawaab).",
        parse_mode="Markdown"
    )

@bot.callback_query_handler(func=lambda c: c.data == "tts_back_to_languages")
def on_back_to_languages_tts(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text="ðŸŽ™ï¸ Choose a language for Text-to-Speech:",
        reply_markup=make_language_keyboard_tts()
    )
    bot.answer_callback_query(call.id)

@bot.callback_query_handler(func=lambda c: c.data.startswith("btn_speak_transcription|"))
def button_speak_transcription_handler(call):
    uid = str(call.from_user.id)
    update_user_activity(uid)
    _, message_id_str = call.data.split("|", 1)
    message_id = int(message_id_str)

    transcription_text = user_transcriptions.get(uid, {}).get(message_id, "")
    if not transcription_text:
        bot.answer_callback_query(call.id, "âŒ No transcription found for this message to speak.")
        return

    bot.answer_callback_query(call.id, "Converting transcription to speech...")
    asyncio.run(synth_and_send_tts(call.message.chat.id, uid, transcription_text, reply_to_message_id=message_id))


# --- General Text Message Handler (for TTS) ---
@bot.message_handler(func=lambda message: message.text and not message.text.startswith('/'))
def handle_general_text_message(message):
    update_user_activity(message.from_user.id)
    # If it's a reply to a bot message, ensure it's not a transcription response itself
    if message.reply_to_message and message.reply_to_message.from_user.id == bot.get_me().id:
        # Avoid processing replies to transcription results again as direct TTS inputs
        # unless it's a specific command related to it.
        # This simple check is for direct text messages, not replies meant for transcription actions.
        # A more robust check might involve checking `user_transcriptions` if the replied message was a transcription.
        pass # Do nothing for replies to bot's own messages unless it's a specific command
    else:
        # If it's a new text message and not a command, treat it as TTS input
        asyncio.run(synth_and_send_tts(message.chat.id, message.from_user.id, message.text, reply_to_message_id=message.message_id))


@bot.message_handler(func=lambda m: True, content_types=['photo', 'sticker', 'document'])
def fallback(message):
    update_user_activity(message.from_user.id)
    bot.send_message(message.chat.id, "Fadlan soo dir oo kaliya fariimo cod, maqal, ama muuqaal ah si aanu u qoro (transcribe) ama fariimo qoraal ah si aanu ugu beddelo cod (text-to-speech).")

@app.route('/', methods=['POST'])
def webhook():
    if request.headers.get('content-type') == 'application/json':
        update = telebot.types.Update.de_json(request.get_data().decode('utf-8'))
        bot.process_new_updates([update])
        return '', 200
    return abort(403)

@app.route('/set_webhook', methods=['GET','POST'])
def set_webhook():
    # Use the main bot's Webhook URL
    url = "https://media-transcriber-bot-hzlk.onrender.com" # Replace with your actual Render URL
    bot.set_webhook(url=url)
    return f"Webhook set to {url}", 200

@app.route('/delete_webhook', methods=['GET','POST'])
def delete_webhook():
    bot.delete_webhook()
    return 'Webhook deleted.', 200

if __name__ == "__main__":
    if os.path.exists(DOWNLOAD_DIR):
        shutil.rmtree(DOWNLOAD_DIR)
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)
    set_bot_info()
    bot.delete_webhook()
    # The webhook URL should be the one for the Render service where this combined bot will be hosted.
    # Make sure to replace "https://media-transcriber-bot-hzlk.onrender.com" with your actual Render URL.
    bot.set_webhook(url="https://media-transcriber-bot-hzlk.onrender.com")
    app.run(host="0.0.0.0", port=int(os.environ.get('PORT', 8080)))
